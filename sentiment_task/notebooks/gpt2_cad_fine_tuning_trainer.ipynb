{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=counterfactual-generation\n",
      "env: WANDB_DISABLED=false\n"
     ]
    }
   ],
   "source": [
    "# %env WANDB_PROJECT=counterfactual-generation\n",
    "# %env WANDB_DISABLED=false\n",
    "import pandas as pd\n",
    "import random\n",
    "import transformers\n",
    "import datasets\n",
    "import sklearn\n",
    "import bs4\n",
    "import wandb\n",
    "import torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def reformat_sentiment(x):\n",
    "    return int(x == 'Positive')\n",
    "\n",
    "def load_dataset(name):\n",
    "    # load the dataset\n",
    "    url = 'https://raw.githubusercontent.com/acmi-lab/counterfactually-augmented-data/master/sentiment/combined/paired/' + name\n",
    "    dataset = pd.read_csv(url, sep='\\t')\n",
    "    dataset.rename(columns={\"Sentiment\": \"sentiment\", \"Text\": \"text\", \"batch_id\": \"paired_id\"}, inplace=True)\n",
    "    # reformat 'sentiment' column\n",
    "    dataset['sentiment'] = dataset['sentiment'].apply(lambda value: reformat_sentiment(value))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def random_shuffle_df(df, seed):\n",
    "    random.seed(seed)\n",
    "    df = sklearn.utils.shuffle(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def set_example_counter(idx, found_idsx):\n",
    "    if idx in found_idsx:\n",
    "        return 0\n",
    "    else:\n",
    "        found_idsx[idx] = 0\n",
    "        return 1\n",
    "\n",
    "def randomly_assign_conterfactuals(df, seed=1):\n",
    "    # prepare the proper Dataframe for the dataset\n",
    "    df = random_shuffle_df(df, seed)\n",
    "    paired_ids = df['paired_id'].values\n",
    "    found_ids = {}\n",
    "    counterfactual_column = []\n",
    "    for idx in paired_ids:\n",
    "        counterfactual_column.append(set_example_counter(idx, found_ids))\n",
    "    df['is_counterfactual'] = counterfactual_column\n",
    "\n",
    "    return df\n",
    "\n",
    "# prepare the dataset with input-counterfactuals instances\n",
    "def prepare_dataframe_with_counterfacuals(df):\n",
    "\n",
    "    # group by paired_id\n",
    "    gb = df.groupby(by=[\"paired_id\"])\n",
    "\n",
    "    # create new columns \"example\" and \"counterfactual\"\n",
    "    example_column = []\n",
    "    counter_column = []\n",
    "    paired_id_column = []\n",
    "    label_ex = []\n",
    "    label_counter = []\n",
    "    for group_id in gb.groups: # group_id == paired_id\n",
    "        group = gb.get_group(group_id)\n",
    "        is_counterfactual_column = group['is_counterfactual'].values\n",
    "        text_column = group['text'].values\n",
    "        sentiment_column = group['sentiment'].values\n",
    "        for is_counter, text, label in zip(is_counterfactual_column,\n",
    "                                           text_column,\n",
    "                                           sentiment_column):\n",
    "            if is_counter:\n",
    "                counter_column.append(text)\n",
    "                label_counter.append(label)\n",
    "            else:\n",
    "                example_column.append(text)\n",
    "                label_ex.append(label)\n",
    "\n",
    "        paired_id_column.append(group_id)\n",
    "\n",
    "    # clean the text from html tags\n",
    "    example_column = [bs4.BeautifulSoup(el, \"lxml\").text for el in example_column]\n",
    "    counter_column = [bs4.BeautifulSoup(el, \"lxml\").text for el in counter_column]\n",
    "\n",
    "    # add the new columns to a new dataframe\n",
    "    d = {'paired_id': paired_id_column,\n",
    "         'example': example_column,\n",
    "         'label_ex': label_ex,\n",
    "         'counterfactual': counter_column,\n",
    "         'label_counter': label_counter}\n",
    "    df_with_counterfactuals = pd.DataFrame(data=d)\n",
    "    df_with_counterfactuals.sort_values(by=\"paired_id\", ascending=True, inplace=True)\n",
    "\n",
    "    return  df_with_counterfactuals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are of type <class 'pandas.core.frame.DataFrame'>\n",
      "# of samples in the training set:3414\n",
      "# of samples in the dev set:490\n",
      "# of samples in the test set:976\n"
     ]
    }
   ],
   "source": [
    "training_set = load_dataset(\"train_paired.tsv\")\n",
    "dev_set = load_dataset(\"dev_paired.tsv\")\n",
    "test_set = load_dataset(\"test_paired.tsv\")\n",
    "print(f\"Datasets are of type {type(test_set)}\")\n",
    "print(f\"# of samples in the training set:{len(training_set)}\")\n",
    "print(f\"# of samples in the dev set:{len(dev_set)}\")\n",
    "print(f\"# of samples in the test set:{len(test_set)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples:4880\n"
     ]
    },
    {
     "data": {
      "text/plain": "   sentiment                                               text  paired_id\n0          0  Long, boring, blasphemous. Never have I been s...          4\n1          1  Long, fascinating, soulful. Never have I been ...          4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n      <th>paired_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Long, boring, blasphemous. Never have I been s...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Long, fascinating, soulful. Never have I been ...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append the 3 datasets\n",
    "imdb_dataframe = pd.concat([training_set, dev_set, test_set], ignore_index=True)\n",
    "print(f\"# of samples:{len(imdb_dataframe)}\")\n",
    "imdb_dataframe.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples:2440\n"
     ]
    },
    {
     "data": {
      "text/plain": "   paired_id                                            example  label_ex  \\\n0          4  Long, fascinating, soulful. Never have I been ...         1   \n1         13  If you haven't seen this, it's terrible. It is...         0   \n\n                                      counterfactual  label_counter  \n0  Long, boring, blasphemous. Never have I been s...              0  \n1  If you haven't seen this, it's incredible. It ...              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paired_id</th>\n      <th>example</th>\n      <th>label_ex</th>\n      <th>counterfactual</th>\n      <th>label_counter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>Long, fascinating, soulful. Never have I been ...</td>\n      <td>1</td>\n      <td>Long, boring, blasphemous. Never have I been s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13</td>\n      <td>If you haven't seen this, it's terrible. It is...</td>\n      <td>0</td>\n      <td>If you haven't seen this, it's incredible. It ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 5\n",
    "df_processed = randomly_assign_conterfactuals(imdb_dataframe.copy(deep=True), random_seed)\n",
    "df_processed = prepare_dataframe_with_counterfacuals(df_processed)\n",
    "print(f\"# of samples:{len(df_processed)}\")\n",
    "df_processed.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples for training:1464\n",
      "# of samples for validation:488\n",
      "# of samples for test:488\n"
     ]
    }
   ],
   "source": [
    "# split into train-val-test (this later will be a 5-cross validation split)\n",
    "random_state = 19\n",
    "train_prop = 0.8 # of the whole dataset\n",
    "val_prop = 0.2 # of the whole dataset\n",
    "df_training = df_processed.sample(frac=train_prop, random_state=random_state)\n",
    "new_val_prop = len(df_processed) * val_prop / len(df_training)\n",
    "\n",
    "df_test = df_processed.drop(df_training.index)\n",
    "\n",
    "df_val = df_training.sample(frac=new_val_prop, random_state=random_state)\n",
    "df_training = df_training.drop(df_val.index)\n",
    "\n",
    "print(f\"# of samples for training:{len(df_training)}\")\n",
    "print(f\"# of samples for validation:{len(df_val)}\")\n",
    "print(f\"# of samples for test:{len(df_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>CFGs for the experiment</h2>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# HERE GOES A CONFIG CELL FOR THE EXPERIMENTS\n",
    "MODEL_NAME = 'sshleifer/tiny-gpt2' #{gpt2 (gpt2-small, 12 layers), gpt2-medium (24 layers), gpt2-large (36 layers), gpt2-xl (48 layers)}\n",
    "FREEZE_PARAMS = False\n",
    "UNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n",
    "SPECIAL_TOKENS = {\"bos_token\": \"<|BOS|>\",\n",
    "                  \"eos_token\": \"<|EOS|>\",\n",
    "                  \"unk_token\": \"<|UNK|>\",\n",
    "                  \"pad_token\": \"<|PAD|>\",\n",
    "                  \"sep_token\": \"<|SEP|>\"} # or set it to None\n",
    "\n",
    "TOKENIZE_IN_BATCH = True\n",
    "\n",
    "NO_CUDA = False\n",
    "EPOCHS = 2\n",
    "LR = 5e-4\n",
    "EPS = 1e-8\n",
    "WARMUP_STEPS = 1e2\n",
    "WEIGHT_DECAY = 0.01\n",
    "USE_APEX = True\n",
    "APEX_OPT_LEVEL  = 'O1'\n",
    "TRAIN_BATCHSIZE = 1\n",
    "EVAL_BATCHSIZE = 1\n",
    "BATCH_UPDATE = 1\n",
    "\n",
    "SEED = 2020\n",
    "WANDB_KEY='ac0eb1b13268d81f2526a3d354e135e6a1ede08c'\n",
    "\n",
    "# set the template for prompting\n",
    "TEMPLATE_PROMPT = \"<bos_token><label_ex> review:<sep><example_text><sep><label_counter> review:<sep><counter_text><eos_token>\"\n",
    "MAP_LABELS = {0:\"Negative\", 1:\"Positive\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      paired_id                                            example  label_ex  \\\n1357      13619  Well , I come from Bulgaria where it 's almost...         1   \n\n                                         counterfactual  label_counter  \\\n1357  Well , I come from Bulgaria where it 's almost...              0   \n\n                                          wrapped_input  \n1357  <|BOS|>Positive review:<|SEP|>Well , I come fr...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paired_id</th>\n      <th>example</th>\n      <th>label_ex</th>\n      <th>counterfactual</th>\n      <th>label_counter</th>\n      <th>wrapped_input</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1357</th>\n      <td>13619</td>\n      <td>Well , I come from Bulgaria where it 's almost...</td>\n      <td>1</td>\n      <td>Well , I come from Bulgaria where it 's almost...</td>\n      <td>0</td>\n      <td>&lt;|BOS|&gt;Positive review:&lt;|SEP|&gt;Well , I come fr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wrap_with_prompt(df_row, template):\n",
    "    final_text = template.replace(\"<label_ex>\", MAP_LABELS[df_row[\"label_ex\"]])\n",
    "    final_text = final_text.replace(\"<example_text>\", df_row[\"example\"])\n",
    "    final_text = final_text.replace(\"<label_counter>\", MAP_LABELS[df_row[\"label_counter\"]])\n",
    "    final_text = final_text.replace(\"<counter_text>\", df_row[\"counterfactual\"])\n",
    "    final_text = final_text.replace(\"<sep>\", SPECIAL_TOKENS[\"sep_token\"])\n",
    "    final_text = final_text.replace(\"<bos_token>\", SPECIAL_TOKENS[\"bos_token\"])\n",
    "    final_text = final_text.replace(\"<eos_token>\", SPECIAL_TOKENS[\"eos_token\"])\n",
    "    return final_text\n",
    "\n",
    "# wrap the datasets with the prompt template\n",
    "df_training[\"wrapped_input\"] = df_training.apply(lambda row: wrap_with_prompt(row, TEMPLATE_PROMPT), axis=1)\n",
    "df_val[\"wrapped_input\"] = df_val.apply(lambda row: wrap_with_prompt(row, TEMPLATE_PROMPT), axis=1)\n",
    "df_test[\"wrapped_input\"] = df_test.apply(lambda row: wrap_with_prompt(row, TEMPLATE_PROMPT), axis=1)\n",
    "df_val.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded tokenizer!\n",
      "Len of tokenizer before adding tokens:50257\n",
      "Added special tokens to tokenizer!\n",
      "Len of tokenizer after adding tokens:50261\n",
      "Downloaded model and cfg!\n"
     ]
    },
    {
     "data": {
      "text/plain": "GPT2Config {\n  \"_name_or_path\": \"sshleifer/tiny-gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 1024,\n  \"n_embd\": 2,\n  \"n_head\": 2,\n  \"n_inner\": null,\n  \"n_layer\": 2,\n  \"n_positions\": 1024,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.14.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50261\n}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load language model objects\n",
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"Downloaded tokenizer!\")\n",
    "if SPECIAL_TOKENS is not None:\n",
    "    print(f\"Len of tokenizer before adding tokens:{len(tokenizer)}\")\n",
    "    tokenizer.add_special_tokens(SPECIAL_TOKENS) # add special tokens\n",
    "    print(\"Added special tokens to tokenizer!\")\n",
    "    print(f\"Len of tokenizer after adding tokens:{len(tokenizer)}\")\n",
    "\n",
    "lm_config_class = transformers.GPT2Config.from_pretrained(MODEL_NAME)\n",
    "lm = transformers.GPT2LMHeadModel.from_pretrained(MODEL_NAME, config=lm_config_class)\n",
    "print(\"Downloaded model and cfg!\")\n",
    "if SPECIAL_TOKENS is not None:\n",
    "    #Special tokens added, model needs to be resized accordingly\n",
    "    lm.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "lm_config_class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "PreTrainedTokenizer(name_or_path='sshleifer/tiny-gpt2', vocab_size=50257, model_max_len=1024, is_fast=False, padding_side='right', special_tokens={'bos_token': '<|BOS|>', 'eos_token': '<|EOS|>', 'unk_token': '<|UNK|>', 'sep_token': '<|SEP|>', 'pad_token': '<|PAD|>'})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the model's layers will be trained!\n"
     ]
    }
   ],
   "source": [
    "if FREEZE_PARAMS:\n",
    "    for parameter in lm.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    for i, m in enumerate(lm.transformer.h):\n",
    "        #Only un-freeze the last n transformer blocks\n",
    "        if i+1 > 12 - UNFREEZE_LAST_N:\n",
    "            for parameter in m.parameters():\n",
    "                parameter.requires_grad = True\n",
    "\n",
    "    for parameter in lm.transformer.ln_f.parameters():\n",
    "        parameter.requires_grad = True\n",
    "\n",
    "    for parameter in lm.lm_head.parameters():\n",
    "        parameter.requires_grad = True\n",
    "    print(f\"Freezed the first {len(lm.transformer.h)-UNFREEZE_LAST_N} model's layers\")\n",
    "    print(f\"Only the last {UNFREEZE_LAST_N} model's layers will be trained!\")\n",
    "else:\n",
    "    print(\"All the model's layers will be trained!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "training_set = datasets.Dataset.from_pandas(df_training)\n",
    "val_set = datasets.Dataset.from_pandas(df_val)\n",
    "test_set = datasets.Dataset.from_pandas(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f99173cb5ea42109f381396e12367d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54be8fd131a24fc488a852ab992d2e36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have been tokenized successfully!\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZE datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"wrapped_input\"], padding=\"max_length\", truncation=True)\n",
    "    # return tokenizer(examples[\"example\"])\n",
    "\n",
    "tokenized_train = training_set.map(tokenize_function, batched=TOKENIZE_IN_BATCH)\n",
    "tokenized_train = tokenized_train.add_column(\"labels\", tokenized_train['input_ids'])\n",
    "\n",
    "tokenized_val = val_set.map(tokenize_function, batched=TOKENIZE_IN_BATCH)\n",
    "tokenized_val = tokenized_val.add_column(\"labels\", tokenized_val['input_ids'])\n",
    "\n",
    "# tokenized_test = test_set.map(tokenize_function, batched=TOKENIZE_IN_BATCH)\n",
    "# tokenized_test.features['labels'] = tokenized_test.features['input_ids']\n",
    "\n",
    "print(\"Datasets have been tokenized successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# tokenized_val.features['label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Start training</h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# cfg_file = \"/home/diego/counterfactuals-generation/sentiment_task/fine_tuning_experiments/settings/tuning_cad_prompt_1.yaml\"\n",
    "cfg_file = \"/home/diego/counterfactuals-generation/sentiment_task/fine_tuning_experiments/settings/configs-default.yaml\"\n",
    "config_dictionary = dict(\n",
    "    yaml=cfg_file,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.12.15 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.14"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/diego/counterfactuals-generation/sentiment_task/notebooks/wandb/run-20220422_174011-hinfjkdc</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/cdiego89/counterfactual-generation/runs/hinfjkdc\" target=\"_blank\">radiant-serenity-9</a></strong> to <a href=\"https://wandb.ai/cdiego89/counterfactual-generation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb.init(config=cfg_file)\n",
    "# wandb.init(project=\"counterfactual-generation\", config={\"num_train_epochs\": EPOCHS, \"learning_rate\": LR})\n",
    "wandb.run.name = 'ciao_5'\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"trained_models/\",\n",
    "    no_cuda=NO_CUDA,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
    "    per_device_eval_batch_size=EVAL_BATCHSIZE,\n",
    "    gradient_accumulation_steps=BATCH_UPDATE,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=transformers.IntervalStrategy.EPOCH,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    learning_rate=LR,\n",
    "    adam_epsilon=EPS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    save_total_limit=1,\n",
    "    save_strategy=transformers.IntervalStrategy.EPOCH,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=[\"wandb\"]  # to log into wandb\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "{'epochs': 100, 'batch_size': 32}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: paired_id, example, label_counter, label_ex, __index_level_0__, wrapped_input, counterfactual.\n",
      "***** Running training *****\n",
      "  Num examples = 1464\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2928\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2928 : < :, Epoch 0.00/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: paired_id, example, label_counter, label_ex, __index_level_0__, wrapped_input, counterfactual.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 488\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to trained_models/checkpoint-1464\n",
      "Configuration saved in trained_models/checkpoint-1464/config.json\n",
      "Model weights saved in trained_models/checkpoint-1464/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: paired_id, example, label_counter, label_ex, __index_level_0__, wrapped_input, counterfactual.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 488\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to trained_models/checkpoint-2928\n",
      "Configuration saved in trained_models/checkpoint-2928/config.json\n",
      "Model weights saved in trained_models/checkpoint-2928/pytorch_model.bin\n",
      "Deleting older checkpoint [trained_models/checkpoint-1464] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from trained_models/checkpoint-2928 (score: 3.6087646484375).\n",
      "Saving model checkpoint to trained_models/\n",
      "Configuration saved in trained_models/config.json\n",
      "Model weights saved in trained_models/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=lm,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc0c180b6d0849c2befec5f4d27080a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▂▄▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▄▅▇██</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>▁█▆▁▅</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>3.60876</td></tr><tr><td>eval/runtime</td><td>8.7139</td></tr><tr><td>eval/samples_per_second</td><td>56.002</td></tr><tr><td>eval/steps_per_second</td><td>56.002</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>2928</td></tr><tr><td>train/learning_rate</td><td>8e-05</td></tr><tr><td>train/loss</td><td>3.5787</td></tr><tr><td>train/total_flos</td><td>2734424064.0</td></tr><tr><td>train/train_loss</td><td>3.57691</td></tr><tr><td>train/train_runtime</td><td>213.2619</td></tr><tr><td>train/train_samples_per_second</td><td>13.73</td></tr><tr><td>train/train_steps_per_second</td><td>13.73</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">radiant-serenity-9</strong>: <a href=\"https://wandb.ai/cdiego89/counterfactual-generation/runs/hinfjkdc\" target=\"_blank\">https://wandb.ai/cdiego89/counterfactual-generation/runs/hinfjkdc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20220422_174011-hinfjkdc/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "1024"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_val['input_ids'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# metric = datasets.load_metric(\"rouge\")\n",
    "metric = datasets.load_metric(\"bleu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Metric(name: \"bleu\", features: {'predictions': Sequence(feature=Value(dtype='string', id='token'), length=-1, id='sequence'), 'references': Sequence(feature=Sequence(feature=Value(dtype='string', id='token'), length=-1, id='sequence'), length=-1, id='references')}, usage: \"\"\"\nComputes BLEU score of translated segments against one or more references.\nArgs:\n    predictions: list of translations to score.\n        Each translation should be tokenized into a list of tokens.\n    references: list of lists of references for each translation.\n        Each reference should be tokenized into a list of tokens.\n    max_order: Maximum n-gram order to use when computing BLEU score.\n    smooth: Whether or not to apply Lin et al. 2004 smoothing.\nReturns:\n    'bleu': bleu score,\n    'precisions': geometric mean of n-gram precisions,\n    'brevity_penalty': brevity penalty,\n    'length_ratio': ratio of lengths,\n    'translation_length': translation_length,\n    'reference_length': reference_length\nExamples:\n\n    >>> predictions = [\n    ...     [\"hello\", \"there\", \"general\", \"kenobi\"],                             # tokenized prediction of the first sample\n    ...     [\"foo\", \"bar\", \"foobar\"]                                             # tokenized prediction of the second sample\n    ... ]\n    >>> references = [\n    ...     [[\"hello\", \"there\", \"general\", \"kenobi\"], [\"hello\", \"there\", \"!\"]],  # tokenized references for the first sample (2 references)\n    ...     [[\"foo\", \"bar\", \"foobar\"]]                                           # tokenized references for the second sample (1 reference)\n    ... ]\n    >>> bleu = datasets.load_metric(\"bleu\")\n    >>> results = bleu.compute(predictions=predictions, references=references)\n    >>> print(results[\"bleu\"])\n    1.0\n\"\"\", stored examples: 0)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /home/diego/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2-medium\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1024,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 1024,\n",
      "  \"n_special\": 0,\n",
      "  \"predict_special_tokens\": true,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized configuration class <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\nModel type should be one of BigBirdPegasusConfig, M2M100Config, LEDConfig, BlenderbotSmallConfig, MT5Config, T5Config, PegasusConfig, MarianConfig, MBartConfig, BartConfig, BlenderbotConfig, FSMTConfig, XLMProphetNetConfig, ProphetNetConfig, EncoderDecoderConfig.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_31513/2163971891.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransformers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAutoModelForSeq2SeqLM\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"gpt2-medium\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/transformers/models/auto/auto_factory.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    436\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mmodel_class\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpretrained_model_name_or_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mmodel_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m         raise ValueError(\n\u001B[0;32m--> 438\u001B[0;31m             \u001B[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    439\u001B[0m             \u001B[0;34mf\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping.keys())}.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m         )\n",
      "\u001B[0;31mValueError\u001B[0m: Unrecognized configuration class <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\nModel type should be one of BigBirdPegasusConfig, M2M100Config, LEDConfig, BlenderbotSmallConfig, MT5Config, T5Config, PegasusConfig, MarianConfig, MBartConfig, BartConfig, BlenderbotConfig, FSMTConfig, XLMProphetNetConfig, ProphetNetConfig, EncoderDecoderConfig."
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\"gpt2-medium\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformers.AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}