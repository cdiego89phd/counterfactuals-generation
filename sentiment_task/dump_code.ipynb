{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python --version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ten = torch.exp(torch.tensor(0.03))\n",
    "print(ten)\n",
    "ten.item()\n",
    "print(type(ten.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sst2 = pd.read_csv(\"sst2_dataset.txt\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sst2.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(sst2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sst2.iloc[2][\"sentence\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wikitext = pd.read_csv(\"wiki.valid.raw\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wikitext.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(wikitext)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sst2 = sst2[\"sentence\"]\n",
    "sst2.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sst2.to_csv(\"sst2_preprocessed.txt\", index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sst2.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(sst2)) < 0.8\n",
    "train = sst2[msk]\n",
    "test = sst2[~msk]\n",
    "print(len(train))\n",
    "train.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.to_csv(\"sst2_train.txt\", index=False, header=False)\n",
    "test.to_csv(\"sst2_test.txt\", index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plm = GPT2LMHeadModel.from_pretrained(\"models/\" + model_name, pad_token_id = tokenizer.eos_token_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DistilBertForMaskedLM\n",
    "\n",
    "\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForMaskedLM.from_pretrained(\n",
    "    \"gpt2_fine_tuned_sst2\",\n",
    "    local_files_only=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.is_cuda"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import polyjuice_nlp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import polyjuice"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# initiate a wrapper.\n",
    "# model path is defaulted to our portable model:\n",
    "# https://huggingface.co/uw-hai/polyjuice\n",
    "# No need to change this unless you are using customized model\n",
    "pj = polyjuice.Polyjuice(model_path=\"uw-hai/polyjuice\", is_cuda=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:polyjuice.polyjuice_wrapper:Setup Polyjuice.\n",
      "INFO:polyjuice.polyjuice_wrapper:Setup SpaCy processor.\n",
      "INFO:polyjuice.polyjuice_wrapper:Setup perplexity scorer.\n"
     ]
    }
   ],
   "source": [
    "# the base sentence\n",
    "text = \"It is great for kids.\"\n",
    "perturbations = pj.perturb(orig_sent=text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:polyjuice.polyjuice_wrapper:Setup SpaCy processor.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_419106/217315759.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0mnum_perturbations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;31m# the function also takes in additional arguments for huggingface generators.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m     \u001B[0mnum_beams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m )\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/polyjuice/polyjuice_wrapper.py\u001B[0m in \u001B[0;36mperturb\u001B[0;34m(self, orig_sent, blanked_sent, is_complete_blank, ctrl_code, perplex_thred, num_perturbations, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    224\u001B[0m         \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetLogger\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"transformers.generation_utils\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetLevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mERROR\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidate_and_load_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"generator\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 226\u001B[0;31m         \u001B[0morig_doc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_sent\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_sent\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0morig_sent\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    227\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mblanked_sent\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m             \u001B[0mblanked_sents\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mblanked_sent\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblanked_sent\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mblanked_sent\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/polyjuice/polyjuice_wrapper.py\u001B[0m in \u001B[0;36m_process\u001B[0;34m(self, sentence)\u001B[0m\n\u001B[1;32m     85\u001B[0m     \u001B[0;31m##############################################\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_process\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 87\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidate_and_load_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"spacy_processor\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mreturn\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     88\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspacy_processor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/polyjuice/polyjuice_wrapper.py\u001B[0m in \u001B[0;36mvalidate_and_load_model\u001B[0;34m(self, model_name)\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m             \u001B[0mloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"_load_{model_name}\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mloader\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mloader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_load_perplex_scorer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/polyjuice/polyjuice_wrapper.py\u001B[0m in \u001B[0;36m_load_spacy_processor\u001B[0;34m(self, is_space_tokenizer)\u001B[0m\n\u001B[1;32m     78\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_load_spacy_processor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_space_tokenizer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Setup SpaCy processor.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspacy_processor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_processor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mis_space_tokenizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/polyjuice/helpers.py\u001B[0m in \u001B[0;36mcreate_processor\u001B[0;34m(is_space_tokenizer)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcreate_processor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mis_space_tokenizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 97\u001B[0;31m     \u001B[0mnlp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspacy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"en_core_web_sm\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     98\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mis_space_tokenizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m         \u001B[0mnlp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_WhitespaceSpacyTokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnlp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvocab\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/spacy/__init__.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(name, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0menable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0menable\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0mexclude\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexclude\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m         \u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m     )\n\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/spacy/util.py\u001B[0m in \u001B[0;36mload_model\u001B[0;34m(name, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[1;32m    434\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mOLD_MODEL_SHORTCUTS\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mIOError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mErrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mE941\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfull\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mOLD_MODEL_SHORTCUTS\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[index]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 436\u001B[0;31m     \u001B[0;32mraise\u001B[0m \u001B[0mIOError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mErrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mE050\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    437\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOSError\u001B[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# perturb the sentence with one line:\n",
    "# When running it for the first time, the wrapper will automatically\n",
    "# load related models, e.g. the generator and the perplexity filter.\n",
    "perturbations = pj.perturb(\n",
    "    orig_sent=text,\n",
    "    # can specify where to put the blank. Otherwise, it's automatically selected.\n",
    "    # Can be a list or a single sentence.\n",
    "    blanked_sent=\"It is [BLANK] for kids.\",\n",
    "    # can also specify the ctrl code (a list or a single code.)\n",
    "    # The code should be from 'resemantic', 'restructure', 'negation', 'insert', 'lexical', 'shuffle', 'quantifier', 'delete'.\n",
    "    ctrl_code=\"negation\",\n",
    "    # Customzie perplexity score.\n",
    "    perplex_thred=5,\n",
    "    # number of perturbations to return\n",
    "    num_perturbations=1,\n",
    "    # the function also takes in additional arguments for huggingface generators.\n",
    "    num_beams=3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "is_cuda = True\n",
    "model_path = \"uw-hai/polyjuice\"\n",
    "generator = pipeline(\"text-generation\",\n",
    "                     model=AutoModelForCausalLM.from_pretrained(model_path),\n",
    "                     max_length=2048,\n",
    "                     tokenizer=AutoTokenizer.from_pretrained(model_path),\n",
    "                     framework=\"pt\", device=0 if is_cuda else -1)\n",
    "\n",
    "prompt_text = \"A dog is embraced by the woman. <|perturb|> [negation] A dog is [BLANK] the woman.\"\n",
    "generator(prompt_text, num_beams=3, num_return_sequences=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prompt_text = \"A dog is embraced by the woman. <|perturb|> [negation] A dog is [BLANK] the woman.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counter_review = \"Because IT IS, that's why! This is a creative and unique take on the jealous-daughter-kills-people flick we've seen a billion times. Rosanna Arquette makes anything worth watching, and Mandy Schaffer's brief nude scene (after teasing via scantily clad attire throughout the film) at the end is yet another reason to watch this fantastic film **** out of ****\t1\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "review_prompt = \"Because IT IS, that's why! This is the same jealous-daughter-kills-people flick we've seen a billion times. Rosanna Arquette makes anything worth watching, and Mandy Schaffer's brief nude scene (after teasing via scantily clad attire throughout the film) at the end almost make this trite blarney worthwhile, but not quite.* out of **** 0 <|perturb|> [BLANK] [SEP]\"\n",
    "\n",
    "# review_prompt = \"Because IT IS, that's why! This is the same jealous-daughter-kills-people flick we've seen a billion times. Rosanna Arquette makes anything worth watching, and Mandy Schaffer's brief nude scene (after teasing via scantily clad attire throughout the film) at the end almost make this trite blarney worthwhile, but not quite.* out of **** 0 <|perturb|> [negation] Because IT IS, that's why! This is the same jealous-daughter-kills-people flick we've seen a billion times. Rosanna Arquette [BLANK], and Mandy Schaffer's brief nude scene (after teasing via scantily clad attire throughout the film) at the end almost make this trite blarney worthwhile, but not quite.* out of **** 0 [SEP]\"\n",
    "\n",
    "# short_review_prompt = \"This is the same jealous-daughter-kills-people flick we've seen a billion times. <|perturb|> [negation] [BLANK]\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator(review_prompt, num_beams=3, num_return_sequences=3)\n",
    "# generator(short_review_prompt, num_beams=3, num_return_sequences=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from polyjuice.generations import ALL_CTRL_CODES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# short_output #[0]['generated_text']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt_text = \"A dog is embraced by the woman. <|perturb|> [negation] [BLANK]\"\n",
    "generator(prompt_text, num_beams=3, num_return_sequences=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dksl = \"There's nothing wrong with a popcorn movie to keep you off the streets. It's just that some are better than others. This is very excellent. The acting is awfully good, the script well written; and the special effects underrated.Why does Hollywood treat it's audience with such intrigue? And why have they not made a sequel?\t1\tThere's nothing wrong with a popcorn movie to keep you off the streets. It's just that some are better than others. This is very poor. The acting is awful, the script dire; and the special effects overrated.Why does Hollywood treat it's audience with such contempt? And why have they made a sequel?\"\n",
    "\n",
    "short_review_prompt = \"There's nothing wrong with a popcorn movie to keep you off the streets.\"\n",
    "generator(short_review_prompt, num_beams=3, num_return_sequences=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6922d7843b8144dbad99a366ea957c51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "840c0a518bbc4847baa5ecacd4a93afa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a6eebb20bbd41f5bbcc1bbacd9f9699"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c9af49fa13a4c3f9fd5a8365b993865"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/336M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5afe16c8bc3b4005be0dc76601410349"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# initialize tokenizer and model from pretrained GPT2 model\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('sshleifer/tiny-gpt2')\n",
    "# model = GPT2LMHeadModel.from_pretrained('sshleifer/tiny-gpt2')\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is out1 == out2?? False\n",
      "\n",
      "Worst movie, (with the best reviews given it) I've ever seen. Over the top dialog, acting, and direction. more slasher flick than thriller.With all the great reviews this movie got I'm appalled that it turned out so silly. I'm not sure why. I'm not sure why. I don't know why. I don't know why. I'm not sure why. I don't know why. I don't know why. I'm not sure why. I don't know why. I'm not sure why. I'm not sure why.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Worst movie, (with the best reviews given it) I've ever seen. Over the top dialog, acting, and direction. more slasher flick than thriller.With all the great reviews this movie got I'm appalled that it turned out so silly. But I was also shocked to see that all those big screen reviews were not the same as this film. I couldn't believe that the action was so bad because I didn't know what to expect. I'm not sure what to expect.The film is very action packed and action packed, the characters are just as strong as the characters in\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Worst movie, (with the best reviews given it) I've ever seen. Over the top dialog, acting, and direction. more slasher flick than thriller.With all the great reviews this movie got I'm appalled that it turned out so silly.\"\n",
    "inputs = tokenizer.encode(sequence, return_tensors='pt')\n",
    "outputs = model.generate(inputs, max_length=120,\n",
    "                         do_sample=True,\n",
    "                         no_repeat_ngram_size=0,\n",
    "                         num_beam=5,\n",
    "                         temperature=0.6,\n",
    "                         num_return_sequences=1)\n",
    "out_1 = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "outputs = model.generate(inputs, max_length=120,\n",
    "                         do_sample=True,\n",
    "                         no_repeat_ngram_size=0,\n",
    "                         num_beam=5,\n",
    "                         temperature=0.6,\n",
    "                         num_return_sequences=1)\n",
    "out_2 = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Is out1 == out2?? {out_1 == out_2}\\n\")\n",
    "print(out_1)\n",
    "print(\"\\n\\n\\n\")\n",
    "print(out_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# import ast\n",
    "import stanza\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# sentences = parser.raw_parse_sents([\"Hello, My name is Melroy.\", \"What is your name?\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT (S (NP (DT This)) (VP (VBZ is) (NP (DT a) (NN test))) (. .)))\n",
      "(ROOT (S (CC But) (NP (DT this)) (VP (VBZ is) (NP (DT the) (JJ second) (NN sentence))) (. .)))\n"
     ]
    }
   ],
   "source": [
    "seed_review = nlp('This is a test. But this is the second sentence. And we made more of it.')\n",
    "for sentence in seed_review.sentences:\n",
    "    print(sentence.constituency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT (S (NP (DT This)) (VP (VBZ is) (NP (DT a) (NN test))) (. .)))\n",
      "(ROOT (S (CC But) (NP (DT this)) (VP (VBZ is) (NP (DT the) (JJ second) (NN sentence))) (. .)))\n"
     ]
    }
   ],
   "source": [
    "counter_review = nlp('This is not a test. But this is the second sentence.')\n",
    "for sentence in counter_review.sentences:\n",
    "    print(sentence.constituency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "True\n",
      "(ROOT (S (NP (DT This)) (VP (VBZ is) (NP (DT a) (NN test))) (. .)))\n",
      "(ROOT (S (CC But) (NP (DT this)) (VP (VBZ is) (NP (DT the) (JJ second) (NN sentence))) (. .)))\n",
      "(ROOT (S (CC And) (NP (PRP we)) (VP (VBD made) (NP (NP (JJR more)) (PP (IN of) (NP (PRP it))))) (. .)))\n",
      "(ROOT (S (NP (DT This)) (VP (VBZ is) (RB not) (NP (DT a) (NN test))) (. .)))\n",
      "(ROOT (S (CC But) (NP (DT this)) (VP (VBZ is) (NP (DT the) (JJ second) (NN sentence))) (. .)))\n",
      "(ROOT (S (CC And) (. .)))\n"
     ]
    }
   ],
   "source": [
    "# parse counter review\n",
    "seed_review = nlp('This is a test. But this is the second sentence. And we made more of it.')\n",
    "\n",
    "# parse generated counter review\n",
    "counter_review = nlp('This is not a test. But this is the second sentence. And.')\n",
    "\n",
    "# check and add empty sentences\n",
    "if len(seed_review.sentences) >= len(counter_review.sentences):\n",
    "    n_to_add = len(seed_review.sentences) - len(counter_review.sentences)\n",
    "    to_add = [nlp(\".\").sentences[0] for i in range(n_to_add)]\n",
    "    counter_review.sentences += to_add\n",
    "else:\n",
    "    n_to_add = len(counter_review.sentences) - len(seed_review.sentences)\n",
    "    to_add = [nlp(\".\").sentences[0] for i in range(n_to_add)]\n",
    "    seed_review.sentences += to_add\n",
    "\n",
    "print(len(seed_review.sentences))\n",
    "print(len(counter_review.sentences))\n",
    "assert len(seed_review.sentences) == len(counter_review.sentences)\n",
    "\n",
    "# print to manual check\n",
    "print(len(seed_review.sentences) == len(counter_review.sentences))\n",
    "for sentence in seed_review.sentences:\n",
    "    print(sentence.constituency)\n",
    "\n",
    "for sentence in counter_review.sentences:\n",
    "    print(sentence.constituency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "stanza.models.common.doc.Document"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seed_review)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "7.0"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zss\n",
    "import numpy as np\n",
    "\n",
    "distances = [zss.simple_distance(s_one.constituency, s_two.constituency) for (s_one, s_two) in zip(seed_review.sentences, counter_review.sentences)]\n",
    "\n",
    "np.mean(distances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Levenshtein\n",
    "Levenshtein.distance(\"ciao\", \"ciao\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import nltk\n",
    "smoothing_function = nltk.translate.bleu_score.SmoothingFunction()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4904617366562973"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = \"my name is Diego and I am fine but feeling odd sometimes. Yes, please. Amigoooooo. no me lo puedo creer\"\n",
    "hypothesis = \"my name is Diego and I am fine but feeling odd sometimes. What about you?\"\n",
    "reference = nltk.tokenize.word_tokenize(reference)\n",
    "hypothesis = nltk.tokenize.word_tokenize(hypothesis)\n",
    "\n",
    "nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, smoothing_function=smoothing_function.method1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4988968343630959"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, smoothing_function=smoothing_function.method2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import fast_bleu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'bigram': [0.7165313105737893, 0.7071067811865476],\n 'trigram': [0.7165313105737893, 0.6299605162718741],\n '4_gram': [0.40293516672844226, 0.3976353643835253]}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_references = [\"I am Diego\", \"I am Diego Carraro\"]\n",
    "list_of_references = [nltk.tokenize.word_tokenize(el) for el in list_of_references]\n",
    "weights = {'bigram': (1/2., 1/2.), 'trigram': (1/3., 1/3., 1/3.), '4_gram': (1/4., 1/4., 1/4., 1/4.)}\n",
    "self_bleu = fast_bleu.SelfBLEU(list_of_references, weights)\n",
    "self_bleu.get_score()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "1.5"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.5 / 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.5 // 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}