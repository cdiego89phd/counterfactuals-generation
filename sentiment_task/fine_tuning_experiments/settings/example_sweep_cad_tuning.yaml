DATASET_PATH: "~/counterfactuals-generation/sentiment_task/cad_imdb/"
OUT_DIR: "~/counterfactuals-generation/sentiment_task/fine_tuning_experiments/sweep_tuning"
N_SWEEP_RUNS: 1

FOLD: "0"

MODEL_FROM_LOCAL: True
MODEL_DIR: "~/counterfactuals-generation/sentiment_task/fine_tuning_experiments/saved_models"
BASE_MODEL: "gpt2"
LM_NAME: "gpt2" #{gpt2 (gpt2-small, 12 layers), gpt2-medium (24 layers), gpt2-large (36 layers), gpt2-xl (48 layers)}

SPECIAL_TOKENS: # or set it to None
  "bos_token": "<|BOS|>"
  "eos_token": "<|EOS|>"
  "unk_token": "<|UNK|>"
  "pad_token": "<|PAD|>"
  "sep_token": "<|SEP|>"
TOKENIZE_IN_BATCH: True
NO_CUDA: False

PROMPT_ID: "1"
TEMPLATE_PROMPT: "<bos_token><label_ex> review:<sep><example_text><sep><label_counter> review:<sep><counter_text><eos_token>"
MAP_LABELS:
  0: "Negative"
  1: "Positive"

