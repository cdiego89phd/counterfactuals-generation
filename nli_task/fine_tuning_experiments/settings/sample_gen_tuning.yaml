DATASET_PATH: "/home/diego/counterfactuals-generation/nli_task/cad_flickr_nli/"
FOLD: "0" # ["0", "1", "2", "3", "4"]
N_SWEEP_RUNS: 1

MODEL_DIR: "/home/diego/counterfactuals-generation/nli_task/fine_tuning_experiments/saved_models"
LM_NAME: "sshleifer/tiny-gpt2@prompt-1@cad_fine_tuning" #{gpt2 (gpt2-small, 12 layers), gpt2-medium (24 layers), gpt2-large (36 layers), gpt2-xl (48 layers)}
BASE_MODEL: "sshleifer/tiny-gpt2"

TASK_NAME: "cad_gen_tuning"

SPECIAL_TOKENS: # or set it to None
  "bos_token": "<|BOS|>"
  "eos_token": "<|EOS|>"
  "unk_token": "<|UNK|>"
  "pad_token": "<|PAD|>"
  "sep_token": "<|SEP|>"
TOKENIZE_IN_BATCH: True
CUDA_DEVICE: 0

CLASSIFIER_NAME: cross-encoder/nli-deberta-v3-large
N_TO_GENERATE: 1
SEED: 2022

PROMPT_ID: "1"
TEMPLATE_PROMPT: "<bos_token>Label: <original_label>\n<sep>P: <P>\n<sep>H: <H>\n<sep>Counterfactual Label: <counter_label>\n<sep><TC>: <counter_text><eos_token>"
GENERATION_PROMPT: "<bos_token>Label: <original_label>\n<sep>P: <P>\n<sep>H: <H>\n<sep>Counterfactual Label: <counter_label>\n<sep><TC>: "
