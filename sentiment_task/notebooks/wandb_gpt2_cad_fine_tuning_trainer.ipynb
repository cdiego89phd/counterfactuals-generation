{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %env WANDB_PROJECT=counterfactual-generation\n",
    "# %env WANDB_DISABLED=false\n",
    "import pandas as pd\n",
    "import random\n",
    "import transformers\n",
    "import datasets\n",
    "import sklearn\n",
    "import bs4\n",
    "import wandb\n",
    "import torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def reformat_sentiment(x):\n",
    "    return int(x == 'Positive')\n",
    "\n",
    "def load_dataset(name):\n",
    "    # load the dataset\n",
    "    url = 'https://raw.githubusercontent.com/acmi-lab/counterfactually-augmented-data/master/sentiment/combined/paired/' + name\n",
    "    dataset = pd.read_csv(url, sep='\\t')\n",
    "    dataset.rename(columns={\"Sentiment\": \"sentiment\", \"Text\": \"text\", \"batch_id\": \"paired_id\"}, inplace=True)\n",
    "    # reformat 'sentiment' column\n",
    "    dataset['sentiment'] = dataset['sentiment'].apply(lambda value: reformat_sentiment(value))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def random_shuffle_df(df, seed):\n",
    "    random.seed(seed)\n",
    "    df = sklearn.utils.shuffle(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def set_example_counter(idx, found_idsx):\n",
    "    if idx in found_idsx:\n",
    "        return 0\n",
    "    else:\n",
    "        found_idsx[idx] = 0\n",
    "        return 1\n",
    "\n",
    "def randomly_assign_conterfactuals(df, seed=1):\n",
    "    # prepare the proper Dataframe for the dataset\n",
    "    df = random_shuffle_df(df, seed)\n",
    "    paired_ids = df['paired_id'].values\n",
    "    found_ids = {}\n",
    "    counterfactual_column = []\n",
    "    for idx in paired_ids:\n",
    "        counterfactual_column.append(set_example_counter(idx, found_ids))\n",
    "    df['is_counterfactual'] = counterfactual_column\n",
    "\n",
    "    return df\n",
    "\n",
    "# prepare the dataset with input-counterfactuals instances\n",
    "def prepare_dataframe_with_counterfacuals(df):\n",
    "\n",
    "    # group by paired_id\n",
    "    gb = df.groupby(by=[\"paired_id\"])\n",
    "\n",
    "    # create new columns \"example\" and \"counterfactual\"\n",
    "    example_column = []\n",
    "    counter_column = []\n",
    "    paired_id_column = []\n",
    "    label_ex = []\n",
    "    label_counter = []\n",
    "    for group_id in gb.groups: # group_id == paired_id\n",
    "        group = gb.get_group(group_id)\n",
    "        is_counterfactual_column = group['is_counterfactual'].values\n",
    "        text_column = group['text'].values\n",
    "        sentiment_column = group['sentiment'].values\n",
    "        for is_counter, text, label in zip(is_counterfactual_column,\n",
    "                                           text_column,\n",
    "                                           sentiment_column):\n",
    "            if is_counter:\n",
    "                counter_column.append(text)\n",
    "                label_counter.append(label)\n",
    "            else:\n",
    "                example_column.append(text)\n",
    "                label_ex.append(label)\n",
    "\n",
    "        paired_id_column.append(group_id)\n",
    "\n",
    "    # clean the text from html tags\n",
    "    example_column = [bs4.BeautifulSoup(el, \"lxml\").text for el in example_column]\n",
    "    counter_column = [bs4.BeautifulSoup(el, \"lxml\").text for el in counter_column]\n",
    "\n",
    "    # add the new columns to a new dataframe\n",
    "    d = {'paired_id': paired_id_column,\n",
    "         'example': example_column,\n",
    "         'label_ex': label_ex,\n",
    "         'counterfactual': counter_column,\n",
    "         'label_counter': label_counter}\n",
    "    df_with_counterfactuals = pd.DataFrame(data=d)\n",
    "    df_with_counterfactuals.sort_values(by=\"paired_id\", ascending=True, inplace=True)\n",
    "\n",
    "    return  df_with_counterfactuals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are of type <class 'pandas.core.frame.DataFrame'>\n",
      "# of samples in the training set:3414\n",
      "# of samples in the dev set:490\n",
      "# of samples in the test set:976\n"
     ]
    }
   ],
   "source": [
    "training_set = load_dataset(\"train_paired.tsv\")\n",
    "dev_set = load_dataset(\"dev_paired.tsv\")\n",
    "test_set = load_dataset(\"test_paired.tsv\")\n",
    "print(f\"Datasets are of type {type(test_set)}\")\n",
    "print(f\"# of samples in the training set:{len(training_set)}\")\n",
    "print(f\"# of samples in the dev set:{len(dev_set)}\")\n",
    "print(f\"# of samples in the test set:{len(test_set)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples:4880\n"
     ]
    },
    {
     "data": {
      "text/plain": "   sentiment                                               text  paired_id\n0          0  Long, boring, blasphemous. Never have I been s...          4\n1          1  Long, fascinating, soulful. Never have I been ...          4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n      <th>paired_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Long, boring, blasphemous. Never have I been s...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Long, fascinating, soulful. Never have I been ...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append the 3 datasets\n",
    "imdb_dataframe = pd.concat([training_set, dev_set, test_set], ignore_index=True)\n",
    "print(f\"# of samples:{len(imdb_dataframe)}\")\n",
    "imdb_dataframe.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples:2440\n"
     ]
    },
    {
     "data": {
      "text/plain": "   paired_id                                            example  label_ex  \\\n0          4  Long, boring, blasphemous. Never have I been s...         0   \n1         13  If you haven't seen this, it's terrible. It is...         0   \n\n                                      counterfactual  label_counter  \n0  Long, fascinating, soulful. Never have I been ...              1  \n1  If you haven't seen this, it's incredible. It ...              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paired_id</th>\n      <th>example</th>\n      <th>label_ex</th>\n      <th>counterfactual</th>\n      <th>label_counter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>Long, boring, blasphemous. Never have I been s...</td>\n      <td>0</td>\n      <td>Long, fascinating, soulful. Never have I been ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13</td>\n      <td>If you haven't seen this, it's terrible. It is...</td>\n      <td>0</td>\n      <td>If you haven't seen this, it's incredible. It ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 5\n",
    "df_processed = randomly_assign_conterfactuals(imdb_dataframe.copy(deep=True), random_seed)\n",
    "df_processed = prepare_dataframe_with_counterfacuals(df_processed)\n",
    "print(f\"# of samples:{len(df_processed)}\")\n",
    "df_processed.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples for training:1464\n",
      "# of samples for validation:488\n",
      "# of samples for test:488\n"
     ]
    }
   ],
   "source": [
    "# split into train-val-test (this later will be a 5-cross validation split)\n",
    "random_state = 19\n",
    "train_prop = 0.8 # of the whole dataset\n",
    "val_prop = 0.2 # of the whole dataset\n",
    "df_training = df_processed.sample(frac=train_prop, random_state=random_state)\n",
    "new_val_prop = len(df_processed) * val_prop / len(df_training)\n",
    "\n",
    "df_test = df_processed.drop(df_training.index)\n",
    "\n",
    "df_val = df_training.sample(frac=new_val_prop, random_state=random_state)\n",
    "df_training = df_training.drop(df_val.index)\n",
    "\n",
    "print(f\"# of samples for training:{len(df_training)}\")\n",
    "print(f\"# of samples for validation:{len(df_val)}\")\n",
    "print(f\"# of samples for test:{len(df_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>CFGs for the experiment</h2>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# HERE GOES A CONFIG CELL FOR THE EXPERIMENTS\n",
    "run_wandb_sweep = True\n",
    "\n",
    "MODEL_NAME = 'sshleifer/tiny-gpt2' #{gpt2 (gpt2-small, 12 layers), gpt2-medium (24 layers), gpt2-large (36 layers), gpt2-xl (48 layers)}\n",
    "FREEZE_PARAMS = False\n",
    "UNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n",
    "SPECIAL_TOKENS = {\"bos_token\": \"<|BOS|>\",\n",
    "                  \"eos_token\": \"<|EOS|>\",\n",
    "                  \"unk_token\": \"<|UNK|>\",\n",
    "                  \"pad_token\": \"<|PAD|>\",\n",
    "                  \"sep_token\": \"<|SEP|>\"} # or set it to None\n",
    "\n",
    "TOKENIZE_IN_BATCH = True\n",
    "\n",
    "SEED = 2020\n",
    "WANDB_KEY='ac0eb1b13268d81f2526a3d354e135e6a1ede08c'\n",
    "\n",
    "# set the template for prompting\n",
    "TEMPLATE_PROMPT = \"<bos_token><label_ex> review:<sep><example_text><sep><label_counter> review:<sep><counter_text><eos_token>\"\n",
    "MAP_LABELS = {0:\"Negative\", 1:\"Positive\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      paired_id                                            example  label_ex  \\\n1357      13619  Well , I come from Bulgaria where it 's almost...         1   \n\n                                         counterfactual  label_counter  \\\n1357  Well , I come from Bulgaria where it 's almost...              0   \n\n                                          wrapped_input  \n1357  <|BOS|>Positive review:<|SEP|>Well , I come fr...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paired_id</th>\n      <th>example</th>\n      <th>label_ex</th>\n      <th>counterfactual</th>\n      <th>label_counter</th>\n      <th>wrapped_input</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1357</th>\n      <td>13619</td>\n      <td>Well , I come from Bulgaria where it 's almost...</td>\n      <td>1</td>\n      <td>Well , I come from Bulgaria where it 's almost...</td>\n      <td>0</td>\n      <td>&lt;|BOS|&gt;Positive review:&lt;|SEP|&gt;Well , I come fr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wrap_with_prompt(df_row, template):\n",
    "    final_text = template.replace(\"<label_ex>\", MAP_LABELS[df_row[\"label_ex\"]])\n",
    "    final_text = final_text.replace(\"<example_text>\", df_row[\"example\"])\n",
    "    final_text = final_text.replace(\"<label_counter>\", MAP_LABELS[df_row[\"label_counter\"]])\n",
    "    final_text = final_text.replace(\"<counter_text>\", df_row[\"counterfactual\"])\n",
    "    final_text = final_text.replace(\"<sep>\", SPECIAL_TOKENS[\"sep_token\"])\n",
    "    final_text = final_text.replace(\"<bos_token>\", SPECIAL_TOKENS[\"bos_token\"])\n",
    "    final_text = final_text.replace(\"<eos_token>\", SPECIAL_TOKENS[\"eos_token\"])\n",
    "    return final_text\n",
    "\n",
    "# wrap the datasets with the prompt template\n",
    "df_training[\"wrapped_input\"] = df_training.apply(lambda row: wrap_with_prompt(row, TEMPLATE_PROMPT), axis=1)\n",
    "df_val[\"wrapped_input\"] = df_val.apply(lambda row: wrap_with_prompt(row, TEMPLATE_PROMPT), axis=1)\n",
    "df_test[\"wrapped_input\"] = df_test.apply(lambda row: wrap_with_prompt(row, TEMPLATE_PROMPT), axis=1)\n",
    "df_val.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded tokenizer!\n",
      "Len of tokenizer before adding tokens:50257\n",
      "Added special tokens to tokenizer!\n",
      "Len of tokenizer after adding tokens:50261\n",
      "Downloaded model and cfg!\n"
     ]
    }
   ],
   "source": [
    "# Load language model objects\n",
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"Downloaded tokenizer!\")\n",
    "if SPECIAL_TOKENS is not None:\n",
    "    print(f\"Len of tokenizer before adding tokens:{len(tokenizer)}\")\n",
    "    tokenizer.add_special_tokens(SPECIAL_TOKENS) # add special tokens\n",
    "    print(\"Added special tokens to tokenizer!\")\n",
    "    print(f\"Len of tokenizer after adding tokens:{len(tokenizer)}\")\n",
    "\n",
    "lm_config_class = transformers.GPT2Config.from_pretrained(MODEL_NAME)\n",
    "lm = transformers.GPT2LMHeadModel.from_pretrained(MODEL_NAME, config=lm_config_class)\n",
    "print(\"Downloaded model and cfg!\")\n",
    "if SPECIAL_TOKENS is not None:\n",
    "    #Special tokens added, model needs to be resized accordingly\n",
    "    lm.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# lm_config_class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the model's layers will be trained!\n"
     ]
    }
   ],
   "source": [
    "if FREEZE_PARAMS:\n",
    "    for parameter in lm.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    for i, m in enumerate(lm.transformer.h):\n",
    "        #Only un-freeze the last n transformer blocks\n",
    "        if i+1 > 12 - UNFREEZE_LAST_N:\n",
    "            for parameter in m.parameters():\n",
    "                parameter.requires_grad = True\n",
    "\n",
    "    for parameter in lm.transformer.ln_f.parameters():\n",
    "        parameter.requires_grad = True\n",
    "\n",
    "    for parameter in lm.lm_head.parameters():\n",
    "        parameter.requires_grad = True\n",
    "    print(f\"Freezed the first {len(lm.transformer.h)-UNFREEZE_LAST_N} model's layers\")\n",
    "    print(f\"Only the last {UNFREEZE_LAST_N} model's layers will be trained!\")\n",
    "else:\n",
    "    print(\"All the model's layers will be trained!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "training_set = datasets.Dataset.from_pandas(df_training)\n",
    "val_set = datasets.Dataset.from_pandas(df_val)\n",
    "test_set = datasets.Dataset.from_pandas(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "897fd5c1cb34462996caec304dcc25be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f07131ca6d3a44baa0177b621ed00a67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have been tokenized successfully!\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZE datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"wrapped_input\"], padding=\"max_length\", truncation=True)\n",
    "    # return tokenizer(examples[\"example\"])\n",
    "\n",
    "tokenized_train = training_set.map(tokenize_function, batched=TOKENIZE_IN_BATCH)\n",
    "tokenized_train = tokenized_train.add_column(\"labels\", tokenized_train['input_ids'])\n",
    "\n",
    "tokenized_val = val_set.map(tokenize_function, batched=TOKENIZE_IN_BATCH)\n",
    "tokenized_val = tokenized_val.add_column(\"labels\", tokenized_val['input_ids'])\n",
    "\n",
    "print(\"Datasets have been tokenized successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Start training</h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mcdiego89\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.12.15 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.14"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/diego/counterfactuals-generation/sentiment_task/notebooks/wandb/run-20220426_130931-xpxhy96z</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/cdiego89/uncategorized/runs/xpxhy96z\" target=\"_blank\">cool-voice-1</a></strong> to <a href=\"https://wandb.ai/cdiego89/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep id:cdiego89/counterfactual-generation/u756ya48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: 0kjponxa with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tBATCH_UPDATE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEPOCHS: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEPS: 0.10879943882850292\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEVAL_BATCHSIZE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tLR: 0.4690756106746647\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tTRAIN_BATCHSIZE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tWARMUP_STEPS: 0.16044444169668887\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tWEIGHT_DECAY: 0.1042792886231348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a315154820db473382cb882ccaf5fb65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">cool-voice-1</strong>: <a href=\"https://wandb.ai/cdiego89/uncategorized/runs/xpxhy96z\" target=\"_blank\">https://wandb.ai/cdiego89/uncategorized/runs/xpxhy96z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20220426_130931-xpxhy96z/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_435211/477121050.py\", line 5, in train\n",
      "    EPOCHS = wandb.config[\"EPOCHS\"]\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_config.py\", line 131, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'EPOCHS'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 3302, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 256, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 222, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1677, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1691, in _finish\n",
      "    if self._wl and len(self._wl._global_run_stack) > 0:\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_setup.py\", line 283, in __getattr__\n",
      "    return getattr(self._instance, name)\n",
      "AttributeError: 'NoneType' object has no attribute '_global_run_stack'\n",
      "\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Sweep Agent: Waiting for job.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Job received.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: rcut7cye with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tBATCH_UPDATE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEPOCHS: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEPS: 0.05996119613120078\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEVAL_BATCHSIZE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tLR: 0.3659559397839835\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tTRAIN_BATCHSIZE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tWARMUP_STEPS: 0.3635644997481206\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tWEIGHT_DECAY: 0.14153499469789735\n",
      "Exception in thread Thread-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_435211/477121050.py\", line 5, in train\n",
      "    EPOCHS = wandb.config[\"EPOCHS\"]\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_config.py\", line 131, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'EPOCHS'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 3302, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 256, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 222, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1677, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1688, in _finish\n",
      "    hook.call()\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 378, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n",
      "\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Sweep Agent: Waiting for job.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Job received.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: wla8djrr with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tBATCH_UPDATE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEPOCHS: 4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEPS: 0.13491409983423425\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEVAL_BATCHSIZE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tLR: 0.18699914418703892\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tTRAIN_BATCHSIZE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tWARMUP_STEPS: 0.3790968207402709\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tWEIGHT_DECAY: 0.4813816999563807\n",
      "Exception in thread Thread-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_435211/477121050.py\", line 5, in train\n",
      "    EPOCHS = wandb.config[\"EPOCHS\"]\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_config.py\", line 131, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'EPOCHS'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 3302, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 256, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 222, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1677, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1688, in _finish\n",
      "    hook.call()\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 378, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n",
      "\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: k7xn56m7 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tBATCH_UPDATE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEPOCHS: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEPS: 0.4810906674856331\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tEVAL_BATCHSIZE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tLR: 0.28943186372027835\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tTRAIN_BATCHSIZE: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tWARMUP_STEPS: 0.0906974795521084\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tWEIGHT_DECAY: 0.11428312394486027\n",
      "Exception in thread Thread-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_435211/477121050.py\", line 5, in train\n",
      "    EPOCHS = wandb.config[\"EPOCHS\"]\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_config.py\", line 131, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'EPOCHS'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 3302, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 256, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 222, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1677, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1688, in _finish\n",
      "    hook.call()\n",
      "  File \"/home/diego/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 378, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wandb agent cdiego89/counterfactual-generation/c3dly89q\n",
    "\n",
    "def train():\n",
    "\n",
    "    NO_CUDA = False\n",
    "    if run_wandb_sweep:\n",
    "        EPOCHS = wandb.config[\"EPOCHS\"]\n",
    "        LR = wandb.config[\"LR\"]\n",
    "        EPS = wandb.config[\"EPS\"]\n",
    "        WARMUP_STEPS = wandb.config[\"WARMUP_STEPS\"]\n",
    "        WEIGHT_DECAY = wandb.config[\"WEIGHT_DECAY\"]\n",
    "        TRAIN_BATCHSIZE = wandb.config[\"TRAIN_BATCHSIZE\"]\n",
    "        EVAL_BATCHSIZE = wandb.config[\"EVAL_BATCHSIZE\"]\n",
    "        BATCH_UPDATE = wandb.config[\"BATCH_UPDATE\"]\n",
    "    else:\n",
    "        EPOCHS = 2\n",
    "        LR = 5e-4\n",
    "        EPS = 1e-8\n",
    "        WARMUP_STEPS = 1e2\n",
    "        WEIGHT_DECAY = 0.01\n",
    "        TRAIN_BATCHSIZE = 1\n",
    "        EVAL_BATCHSIZE = 1\n",
    "        BATCH_UPDATE = 1\n",
    "\n",
    "    training_args = transformers.TrainingArguments(\n",
    "        output_dir=\"trained_models/\",\n",
    "        no_cuda=NO_CUDA,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
    "        per_device_eval_batch_size=EVAL_BATCHSIZE,\n",
    "        gradient_accumulation_steps=BATCH_UPDATE,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=transformers.IntervalStrategy.EPOCH,\n",
    "        warmup_steps=WARMUP_STEPS,\n",
    "        learning_rate=LR,\n",
    "        adam_epsilon=EPS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        save_total_limit=1,\n",
    "        save_strategy=transformers.IntervalStrategy.EPOCH,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=[\"wandb\"]  # to log into wandb\n",
    "    )\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=lm,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # loss = random.random()\n",
    "    # wandb.log(dict(loss=loss))\n",
    "    # print(f\"Loss reported:{loss}\")\n",
    "\n",
    "# initialize WANDB logging system\n",
    "wandb.login()\n",
    "# wandb.init(group=\"example\")\n",
    "wandb.init()\n",
    "sweep_id = \"cdiego89/counterfactual-generation/u756ya48\"\n",
    "print(f\"Sweep id:{sweep_id}\")\n",
    "wandb.agent(sweep_id, train, count=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ZMQDisplayPublisher' object has no attribute '_orig_publish'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_435211/1235061223.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mwandb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinish\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001B[0m in \u001B[0;36mfinish\u001B[0;34m(exit_code, quiet)\u001B[0m\n\u001B[1;32m   3300\u001B[0m     \"\"\"\n\u001B[1;32m   3301\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mwandb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3302\u001B[0;31m         \u001B[0mwandb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinish\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexit_code\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexit_code\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquiet\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mquiet\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3303\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3304\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    254\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDummy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 256\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    258\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    220\u001B[0m                     \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m                 \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_attaching\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001B[0m in \u001B[0;36mfinish\u001B[0;34m(self, exit_code, quiet)\u001B[0m\n\u001B[1;32m   1675\u001B[0m             \u001B[0mquiet\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mSet\u001B[0m \u001B[0mto\u001B[0m \u001B[0mtrue\u001B[0m \u001B[0mto\u001B[0m \u001B[0mminimize\u001B[0m \u001B[0mlog\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1676\u001B[0m         \"\"\"\n\u001B[0;32m-> 1677\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_finish\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexit_code\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquiet\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1678\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1679\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_finish\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexit_code\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquiet\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mbool\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001B[0m in \u001B[0;36m_finish\u001B[0;34m(self, exit_code, quiet)\u001B[0m\n\u001B[1;32m   1686\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_teardown_hooks\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1687\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstage\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mTeardownStage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEARLY\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1688\u001B[0;31m                 \u001B[0mhook\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1689\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1690\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_atexit_cleanup\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexit_code\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexit_code\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/deeptransformers/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001B[0m in \u001B[0;36m_jupyter_teardown\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    376\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;34m\"_pause_backend\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    377\u001B[0m                 \u001B[0mipython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevents\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munregister\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"post_run_cell\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 378\u001B[0;31m         \u001B[0mipython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplay_pub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpublish\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mipython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplay_pub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_orig_publish\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    379\u001B[0m         \u001B[0;32mdel\u001B[0m \u001B[0mipython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplay_pub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_orig_publish\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(tokenized_val['input_ids'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# metric = datasets.load_metric(\"rouge\")\n",
    "metric = datasets.load_metric(\"bleu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\"gpt2-medium\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformers.AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}