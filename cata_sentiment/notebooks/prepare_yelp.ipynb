{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>YELP restaurants</h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "yelp_data = load_dataset(\"yelp_polarity\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Total length of polarity yelp test {len(yelp_data['test'])}\")\n",
    "print(\"\")\n",
    "\n",
    "texts = yelp_data[\"test\"][\"text\"]\n",
    "labels = yelp_data[\"test\"][\"label\"]\n",
    "\n",
    "d = {\"text\": texts,\n",
    "     \"label\": labels,\n",
    "}\n",
    "\n",
    "df_yelp = pd.DataFrame(data=d)\n",
    "df_yelp[\"sentiment\"] = df_yelp.apply(lambda row: \"positive\" if row['label'] else \"negative\", axis=1)\n",
    "df_yelp.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "texts = df_yelp[\"text\"].values\n",
    "lens = [len(el) for el in texts]\n",
    "print(f\"Max len: {np.max(lens)}\")\n",
    "print(f\"Mean len: {np.mean(lens)}\")\n",
    "print(f\"Min len: {np.min(lens)}\")\n",
    "\n",
    "df_yelp[\"sentiment\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out reviews longer than 2000 and shorter than 10\n",
    "texts = df_yelp[\"text\"].values\n",
    "df_yelp[\"review_len\"] = [len(el) for el in texts]\n",
    "df_yelp = df_yelp[(df_yelp[\"review_len\"] <= 2000) & (df_yelp[\"review_len\"] >= 10)].copy()\n",
    "\n",
    "lens = [len(el) for el in df_yelp[\"text\"].values]\n",
    "print(f\"Max len: {np.max(lens)}\")\n",
    "print(f\"Mean len: {np.mean(lens)}\")\n",
    "print(f\"Min len: {np.min(lens)}\")\n",
    "\n",
    "df_yelp[\"label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pos = df_yelp[df_yelp[\"label\"] == 1].copy()\n",
    "df_neg = df_yelp[df_yelp[\"label\"] == 0].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample 10k instances - 5k positive, 5k negative. Train-test split 80%-20%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "# sample positive and negative labels\n",
    "data_pos = df_pos.sample(n=5000, replace=False, random_state=seed)\n",
    "data_neg = df_neg.sample(n=5000, replace=False, random_state=seed)\n",
    "\n",
    "# sample train-test split positive labels (80-20)%\n",
    "test_pos = data_pos.sample(frac=0.2, replace=False, random_state=seed)\n",
    "train_pos = data_pos[~data_pos.index.isin(test_pos.index)]\n",
    "\n",
    "# sample train-test split negative labels (80-20)%\n",
    "test_neg = data_neg.sample(frac=0.2, replace=False, random_state=seed)\n",
    "train_neg = data_neg[~data_neg.index.isin(test_neg.index)]\n",
    "\n",
    "# build train and test\n",
    "testset = test_neg.append(test_pos)\n",
    "trainset = train_neg.append(train_pos)\n",
    "\n",
    "print()\n",
    "print(f\"len test: {len(testset)}\")\n",
    "print(f\"len train: {len(trainset)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testset.to_csv(\"../yelp/test.csv\", sep=\"\\t\", index=False)\n",
    "trainset.to_csv(\"../yelp/train.csv\", sep=\"\\t\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## n=5k & m=2.5k (n=2m)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 5000\n",
    "m = 2500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(\"../yelp/train.csv\", sep=\"\\t\")\n",
    "len(trainset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = trainset.sample(n=n+m, replace=False, random_state=seed)\n",
    "df_n = df_origin.sample(n=n, replace=False, random_state=seed)\n",
    "df_seed = df_n.sample(n=m, replace=False, random_state=seed)\n",
    "\n",
    "print(f\"len origin: {len(df_origin)}\")\n",
    "print(f\"len n_data: {len(df_n)}\")\n",
    "print(f\"len seed: {len(df_seed)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin.to_csv(\"../yelp/n_5k-m_2.5k/origin_data.csv\", sep=\"\\t\", index=False)\n",
    "df_n.to_csv(\"../yelp/n_5k-m_2.5k/n_data.csv\", sep=\"\\t\", index=False)\n",
    "df_seed.to_csv(\"../yelp/n_5k-m_2.5k/seed_data.csv\", sep=\"\\t\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final size of each training set will be m+m+m=2m+m=n+m. The following sets are sampled from train.csv\n",
    "\n",
    "- origin.csv stores n+m original data points\n",
    "- m_data.csv\n",
    "- seed_data.csv is a sample (size m) from n_data\n",
    "\n",
    "You now need to produce m countefactuals from seed_data!! You will then use n_data.csv and m generated counterfactuals to train your classfier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
