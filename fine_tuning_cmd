python run_lm_finetuning.py output_dir=gpt2_finetuned_sst2 --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=sst2_train.txt --per_gpu_train_batch_size=2 --do_eval --evaluate_during_training --eval_data_file=sst2_test.txt --save_total_limit=1 --learning_rate=0.00001 --num_train_epochs=5 --save_steps=2000

python run_lm_finetuning.py --output_dir=gpt2_fine_tuned_sst2 --model_type=distilbert --model_name_or_path=distilbert-base-uncased --do_train --train_data_file=sst2_train.txt --per_gpu_train_batch_size=1 --do_eval --evaluate_during_training --eval_data_file=sst2_test.txt --save_total_limit=1 --num_train_epochs=1 --save_steps=2000 --mlm

python run_lm_finetuning.py output_dir=gpt2_finetuned_sst2_1 --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=sst2_train.txt --per_gpu_train_batch_size=2 --do_eval --evaluate_during_training --eval_data_file=sst2_test.txt --save_total_limit=1 --learning_rate=0.00001 --num_train_epochs=5 --save_steps=2000


--output_dir=gpt2_fine_tuned_sst2 --model_type=distilbert --model_name_or_path=distilbert-base-uncased --do_train --train_data_file=sentiment_task/imdb_counter_train.txt --per_gpu_train_batch_size=1 --do_eval --evaluate_during_training --eval_data_file=sst2_test.txt --save_total_limit=1 --num_train_epochs=1 --save_steps=2000 --mlm
